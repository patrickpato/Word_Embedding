{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom keras.models import Input, Model\nfrom keras.layers import Dense\nfrom scipy import sparse\nimport numpy as np \nfrom nltk.corpus import stopwords\nimport nltk\nimport pandas as pd\nimport re\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":34,"outputs":[{"output_type":"stream","text":"/kaggle/input/quantum-physics-articles-on-arxiv-1994-to-2009/ArXiv_old.csv\n/kaggle/input/sample-word-embedding-data/sample.csv\n/kaggle/input/titanates/samplefile.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping\nearlystop = EarlyStopping(monitor = 'val_loss',\n                          min_delta = 0,\n                          patience = 5,\n                          verbose = 1,\n                          restore_best_weights = True)","execution_count":35,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#creating a method that creates a dictionary where the keys are unique words and key values are indices\ndef create_unique_word_dict(text:list) -> dict:\n    #obtaining the unique words from the text and sorting them alphabetically\n    words = list(set(text))\n    words.sort()\n    #creating the dictionary for the unique words\n    unique_word_dict = {}\n    for i, word in enumerate(words):\n        unique_word_dict.update({\n            word:i\n        })\n    return unique_word_dict\ndef text_preprocessing(\ntext:list, \npunctuations = r'''!()-[]{};:'\"\\,<>./?@#$%^&*_\"~''',\nstop_words = nltk.corpus.stopwords.words('english') ) -> list:\n    for x in text.lower():\n        if x in punctuations:\n            text = text.replace(x, \"\")\n    #removing numbers\n    text = re.sub(r'\\w*\\d\\w*', '', text)\n    \n    #removing digits\n    text = re.sub(r'[0-9]+', '', text)\n    #removing whitespace\n    text = re.sub(r'\\s+', ' ', text).strip()\n    #lowercase\n    text = text.lower()\n    #converting the text to a list\n    text = text.split(' ')\n    #dropping empty strings\n    text = [x for x in text if x!='']\n    #dropping stopwords\n    text = [x for x in text if x not in stop_words]\n    \n    return text\n#function that finds most similar word based on Eucledian distance or cosine distance\ndef euclidean(vec1:np.array, vec2:np.array) -> float:\n    #calculating the euclidean distance between two vectors\n    return np.sqrt(np.sum((vec1-vec2)**2))\ndef find_similar(word:str, embedding_dict:dict, top_n=10) -> list:\n    #creating a method that finds the most similar words based on learned embeddings\n    dist_dict = {}\n    word_vector = embedding_dict.get(word, [])\n    if len(word_vector) > 0:\n        for key, value in embedding_dict.items():\n            if key!=word:\n                dist = euclidean(word_vector, value)\n                dist_dict.update({\n                    key: dist\n                })\n        return sorted(dist_dict.items(), key=lambda x: x[1])[0:top_n]\n    \n    \n    \n    \n    ","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/quantum-physics-articles-on-arxiv-1994-to-2009/ArXiv_old.csv', error_bad_lines=False)\ndata.info()","execution_count":37,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 27738 entries, 0 to 27737\nData columns (total 6 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   title       27738 non-null  object\n 1   abstract    27738 non-null  object\n 2   categories  27738 non-null  object\n 3   created     27738 non-null  object\n 4   id          27738 non-null  object\n 5   doi         17184 non-null  object\ndtypes: object(6)\nmemory usage: 1.3+ MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.loc[:100]\ndata.info()","execution_count":38,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 101 entries, 0 to 100\nData columns (total 6 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   title       101 non-null    object\n 1   abstract    101 non-null    object\n 2   categories  101 non-null    object\n 3   created     101 non-null    object\n 4   id          101 non-null    object\n 5   doi         66 non-null     object\ndtypes: object(6)\nmemory usage: 4.9+ KB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":39,"outputs":[{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"                                               title  \\\n0  A limit relation for entropy and channel capac...   \n1                          Visualizing Teleportation   \n2  Lower ground state due to counter-rotating wav...   \n3  A Single Trapped Ion as a Time-Dependent Harmo...   \n4  Topological defects, geometric phases, and the...   \n\n                                            abstract  \\\n0  In a quantum mechanical model, Diosi, Feldmann...   \n1  A novel way of picturing the processing of qua...   \n2  We consider a single ion confined in a trap un...   \n3  We show how a single trapped ion may be used t...   \n4  Recent reports on the intriguing features of v...   \n\n                         categories     created         id  \\\n0  ['quant-ph', 'cs.IT', 'math.IT']  2007-04-01  0704.0046   \n1     ['physics.ed-ph', 'quant-ph']  2007-04-02  0704.0051   \n2                      ['quant-ph']  2007-04-01  0704.0117   \n3                      ['quant-ph']  2007-04-02  0704.0135   \n4                      ['quant-ph']  2007-04-02  0704.0137   \n\n                           doi  \n0            10.1063/1.2779138  \n1                          NaN  \n2  10.1088/0953-4075/40/11/002  \n3   10.1103/PhysRevA.76.052105  \n4                          NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>abstract</th>\n      <th>categories</th>\n      <th>created</th>\n      <th>id</th>\n      <th>doi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A limit relation for entropy and channel capac...</td>\n      <td>In a quantum mechanical model, Diosi, Feldmann...</td>\n      <td>['quant-ph', 'cs.IT', 'math.IT']</td>\n      <td>2007-04-01</td>\n      <td>0704.0046</td>\n      <td>10.1063/1.2779138</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Visualizing Teleportation</td>\n      <td>A novel way of picturing the processing of qua...</td>\n      <td>['physics.ed-ph', 'quant-ph']</td>\n      <td>2007-04-02</td>\n      <td>0704.0051</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Lower ground state due to counter-rotating wav...</td>\n      <td>We consider a single ion confined in a trap un...</td>\n      <td>['quant-ph']</td>\n      <td>2007-04-01</td>\n      <td>0704.0117</td>\n      <td>10.1088/0953-4075/40/11/002</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A Single Trapped Ion as a Time-Dependent Harmo...</td>\n      <td>We show how a single trapped ion may be used t...</td>\n      <td>['quant-ph']</td>\n      <td>2007-04-02</td>\n      <td>0704.0135</td>\n      <td>10.1103/PhysRevA.76.052105</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Topological defects, geometric phases, and the...</td>\n      <td>Recent reports on the intriguing features of v...</td>\n      <td>['quant-ph']</td>\n      <td>2007-04-02</td>\n      <td>0704.0137</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#texts = data.abstract\n\ntexts = [x for x in data['abstract']]\n#defining the window size of the context\nwindow = 5\n#creating a placeholder for the scanning of the wordlist\nword_lists = []\nall_text = []\n\nfor text in texts:\n    text = text_preprocessing(text)\n    all_text += text\n    #creating a context dictionary\n    for i, word in enumerate(text):\n        for w in range(window):\n            #obtaining context before the window words\n            if i + 1+ w <len(text):\n                word_lists.append([word] + [text[(i + 1 + w)]])\n            #obtaining context behind the window word\n            if i - w - 1 >= 0:\n                word_lists.append([word] + [text[(i-w-1)]])\nunique_word_dict = create_unique_word_dict(all_text)\n#defining the number of features(our unique words)\nn_words = len(unique_word_dict)\n#obtaining all the uniue words\nwords = list(unique_word_dict.keys())\n#creation of X and Y matrices using OHE\nX = []\nY = []\nfor i, word_list in tqdm(enumerate(word_lists)):\n    #obtaining indices\n    main_word_index = unique_word_dict.get(word_list[0])\n    context_word_index = unique_word_dict.get(word_list[1])\n    #creating placeholders\n    X_row = np.zeros(n_words)\n    Y_row = np.zeros(n_words)\n    \n    #OHEing the main word\n    X_row[main_word_index] = 1\n    #OHEing the y matrix words\n    Y_row[context_word_index] = 1\n    \n    #appending the main matrices\n    X.append(X_row)\n    Y.append(Y_row)\n    \n","execution_count":40,"outputs":[{"output_type":"stream","text":"59750it [00:03, 18172.51it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting the matrices to sparse format to adress the majority of the zeros in the data\nX = sparse.csr_matrix(X)\nY = sparse.csr_matrix(Y)","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#defining the embedding size\nemb_size = 100\n#creating the neural network\ninp = Input(shape = (X.shape[1], ))\nx = Dense(units = emb_size, activation = 'linear')(inp)\nx = Dense(units = Y.shape[1], activation='softmax')(x)\nmodel = Model(inputs=inp, output=x)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n#optimization of the network weights\nmodel.fit(x=X, y=Y, batch_size=256, epochs=150)\n","execution_count":42,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n  import sys\n","name":"stderr"},{"output_type":"error","ename":"TypeError","evalue":"unsupported operand type(s) for +: 'EarlyStopping' and 'list'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-88d8ea48419d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#optimization of the network weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mearlystop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    106\u001b[0m         _callbacks.append(\n\u001b[1;32m    107\u001b[0m             cbks.ProgbarLogger(count_mode, stateful_metrics=model.metrics_names[1:]))\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0m_callbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallbackList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mout_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_labels\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'EarlyStopping' and 'list'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#obtaining the weights from the neural network\n#the weights are also known as the word embeddings\nweights = model.get_weights()[0]\n#creating a dictionary to store the computed weights\n#key is the unique word\n#value is the associated vector\nembedding_dict = {}\nfor word in words:\n    embedding_dict.update({\n        word: weights[unique_word_dict.get(word)]\n        })\n#Vizualizing the embeddings\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10, 10))\nfor word in list(unique_word_dict.keys()):\n  coord = embedding_dict.get(word)\n  plt.scatter(coord[0], coord[1])\n  plt.annotate(word, (coord[0], coord[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}